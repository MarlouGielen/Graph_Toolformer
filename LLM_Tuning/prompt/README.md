# Graph reasoning prompt datasets for LLMs fine-tuning. 

## 1. Contents

This directory contains the graph reasoning prompts for 15 different graph datasets. They all have their corresponding raw graph datasets (which can be downloaded from [**this page**](https://github.com/jwzhanggy/Graph_Toolformer/tree/main/Graph_Toolformer_Package#graph-datasets-used-in-graph-toolformer)).

Each directory contains the train/test graph reasoning tuples for different graph datasets.

- **mixed**: it merges all train/test prompts from all the following 15 graph dataset (except the graph_data_loading), we will use this for the LLM tuning.



- **graph_properties**: it contains the train/test prompts for the gpr dataset created in this paper on graph property reasoning
- **bibliographic_networks**: it contains the train/test prompts for 3 bibliographc network reasoning datasets, cora, pubmed, citeseer
- **molecular_graphs**: it contains the train/test prompts for 4 molecular graph reasoning datasets, proteins, mutag, nci1, ptc
- **recommender_systems**: it contains the train/test prompts for 3 recommender system reasoning datasets, amazon, last-fm, movielens
- **social_networks**: it contains the train/test prompts for 2 social network reasoning datasets, foursquare, twitter
- **knowledge_graphs**: it contains the train/test prompts for 2 knowledge graph reasoning datasets, wordnet, freebase

These above prmopts are all created with prompt templates augmented by ChatGPT based on the concrete graph datasets. In the prompts, we will use the concrete data instances, node ids, relations, and reasoning outputs. 

In addition to these prompts corresponding to concrete graph datasets, we also include a prompt dataset purely generated by chatgpt on graph loading:

- **graph_data_loading**: it contains the pure-chatgpt generated graph data loading prompts

## 2. Prompt format

Each of the above directory contains two files: **prompts_train**, **prompts_test**, denoting the prompts for training and testing, respectively.

Each prompt instance in the training/testing sets has 3 entries: Input, Output, Reasoning Result.

- **Input**: The input contains the potential query inputs to the Graph-toolformers.
- **Output**: The output will be the annotated query output generated by the LLMs with added graph reasoning API calls.
- **Reasoning Result**: We also add the reasoning result for many prompt tupes, which will be used for reasoning result evaluation only.
